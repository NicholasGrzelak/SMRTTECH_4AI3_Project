{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpuvgzIL2N8m"
      },
      "source": [
        "#**SMRTTECH 4AI3 Final Project**\n",
        "\n",
        "Group: 6\n",
        "\n",
        "Thomas French, Nicholas Grzelak"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8S5Xrxnd3mjO"
      },
      "source": [
        "# Import Needed Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "b65eR8KW23EZ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.models import Sequential,load_model\n",
        "from keras.layers import InputLayer, Reshape, Conv2DTranspose, LeakyReLU, ReLU\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, Activation\n",
        "from keras.utils import plot_model\n",
        "from keras.optimizers import Adam\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgeVoom02RYi"
      },
      "source": [
        "#Make Custom Functions\n",
        "**Define Discriminator**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "DLnF5n__2XPd"
      },
      "outputs": [],
      "source": [
        "def define_discriminator(in_shape,modname):\n",
        "\tmodel = Sequential(name=modname)\n",
        "\tmodel.add(Conv2D(32, (3,3), strides=(2, 2), padding='same', input_shape=in_shape))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Conv2D(64, (3,3), strides=(2, 2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# compile model\n",
        "\topt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\treturn model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbjQhp7o20Bo"
      },
      "source": [
        "**Define Generator**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "IDqvGqNY20YR"
      },
      "outputs": [],
      "source": [
        "def define_generator(latent_dim,modname):\n",
        "\tmodel = Sequential(name=modname)\n",
        "\n",
        "\tn_nodes = 128 * 8 * 8\n",
        "\tmodel.add(Dense(n_nodes, input_dim=latent_dim))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Reshape((8, 8, 128)))\n",
        "\n",
        "\tmodel.add(Conv2DTranspose(64, (3,3), strides=(2,2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "\tmodel.add(Conv2DTranspose(32, (3,3), strides=(2,2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "\tmodel.add(Conv2D(3, (3,3), activation='tanh', padding='same'))\n",
        "\treturn model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6sKwW9o3AEO"
      },
      "source": [
        "**Define GAN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qVPBvF583Alr"
      },
      "outputs": [],
      "source": [
        "def define_gan(generator, discriminator,modname):\n",
        "\n",
        "\tdiscriminator.trainable = False\n",
        "\n",
        "\tmodel = Sequential(name=modname)\n",
        "\tmodel.add(generator)\n",
        "\tmodel.add(discriminator)\n",
        "\n",
        "\topt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=opt)\n",
        "\treturn model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lkv2WIHw3Gqb"
      },
      "source": [
        "**Define Getting Real Samples**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "nzNz_JHQ3MAQ"
      },
      "outputs": [],
      "source": [
        "def generate_real_samples(dataset, n_samples):\n",
        "\tix = np.random.randint(0, dataset.shape[0], n_samples)\n",
        "\tX = dataset[ix]\n",
        "\ty = np.ones((n_samples, 1))\n",
        "\treturn X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIZtKCkP3MQl"
      },
      "source": [
        "**Define Getting AI Samples**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "_FzYnG-X3Mia"
      },
      "outputs": [],
      "source": [
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "  x_input = np.random.randn(latent_dim * n_samples)\n",
        "  x_input = x_input.reshape(n_samples, latent_dim)\n",
        "  #Normally verbose = 'auto'\n",
        "  X = generator.predict(x_input,verbose = 0)\n",
        "  y = np.zeros((n_samples, 1))\n",
        "  return X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDDhIQBc3MwH"
      },
      "source": [
        "**Define Saving Plots**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "51xIwk6Q3NBV"
      },
      "outputs": [],
      "source": [
        "def save_plot(examples, epoch, n=10):\n",
        "\tfor i in range(n * n):\n",
        "\t\tplt.subplot(n, n, 1 + i)\n",
        "\t\tplt.axis('off')\n",
        "\t\tplt.imshow(examples[i, :, :, :])\n",
        "\tfilename = 'generated_plot_e%03d.png' % (epoch+1)\n",
        "\tplt.savefig(filename)\n",
        "\tplt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbZJ2V3A3ec0"
      },
      "source": [
        "**Define Evaluator**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vf6haeXY3e1l"
      },
      "outputs": [],
      "source": [
        "def evaluate(epoch, generator, discriminator, dataset, latent_dim, n_samples=100):\n",
        "\tX_real, y_real = generate_real_samples(dataset, n_samples)\n",
        "\t_, acc_real = discriminator.evaluate(X_real, y_real, verbose=0)\n",
        "\n",
        "\tx_fake, y_fake = generate_fake_samples(generator, latent_dim, n_samples)\n",
        "\t_, acc_fake = discriminator.evaluate(x_fake, y_fake, verbose=0)\n",
        "\n",
        "\tprint('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n",
        "\n",
        "\tsave_plot(x_fake, epoch)\n",
        "\tfilename = 'generator_model_%03d.h5' % (epoch + 1)\n",
        "\tgenerator.save(filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxpJMnp3KK7l"
      },
      "source": [
        "**Define Loss Writer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "w6kaE_IaKLS9"
      },
      "outputs": [],
      "source": [
        "def writetxt(name,txtlist):\n",
        "  f = open(name +\".txt\", \"w+\")\n",
        "  for i in txtlist:\n",
        "    f.write(str(i)+'\\n')\n",
        "  f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQIv4Z0631dE"
      },
      "source": [
        "#Training GAN\n",
        "**Get Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "LHJjxmkC4Lzx"
      },
      "outputs": [],
      "source": [
        "#Download the dataset\n",
        "(x_train,y_train),(x_test,y_test)=tf.keras.datasets.cifar10.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49SA4T227ZiG"
      },
      "source": [
        "**Visualize Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8xZwrQG7aFC"
      },
      "outputs": [],
      "source": [
        "#Visualize the Dataset\n",
        "class_names = ['Airplane','Automobile','Bird','Cat','Deer','Dog','Frog','Horse','Ship','Truck']\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(x_train[i], cmap=plt.cm.gray)\n",
        "    plt.xlabel(class_names[int(y_train[i])])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LfckVZw4Nvt"
      },
      "source": [
        "**Normalize Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "dNoq3fNc4QcP"
      },
      "outputs": [],
      "source": [
        "#Normalize Data\n",
        "train_images = x_train / 255.0\n",
        "test_images = x_test / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfYszZklAx-V"
      },
      "source": [
        "**Hyperparameter Initalization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "bP-Xwb29AyWj"
      },
      "outputs": [],
      "source": [
        "batch_size = 256\n",
        "n_epochs = 2\n",
        "bat_per_epo = int(train_images.shape[0] / batch_size)\n",
        "half_batch = int(batch_size / 2)\n",
        "latent_dim = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJIwRvxG4Qzz"
      },
      "source": [
        "**Build Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SNKoa9ESjxt",
        "outputId": "fa9b850e-2709-49e2-ec6e-8d366ab8675d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_33 (Conv2D)          (None, 16, 16, 32)        896       \n",
            "                                                                 \n",
            " leaky_re_lu_55 (LeakyReLU)  (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_34 (Conv2D)          (None, 8, 8, 64)          18496     \n",
            "                                                                 \n",
            " leaky_re_lu_56 (LeakyReLU)  (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " flatten_11 (Flatten)        (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 1)                 4097      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23489 (91.75 KB)\n",
            "Trainable params: 23489 (91.75 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Model: \"Generator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_23 (Dense)            (None, 8192)              827392    \n",
            "                                                                 \n",
            " leaky_re_lu_57 (LeakyReLU)  (None, 8192)              0         \n",
            "                                                                 \n",
            " reshape_11 (Reshape)        (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_22 (Conv2  (None, 16, 16, 64)        73792     \n",
            " DTranspose)                                                     \n",
            "                                                                 \n",
            " leaky_re_lu_58 (LeakyReLU)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_23 (Conv2  (None, 32, 32, 32)        18464     \n",
            " DTranspose)                                                     \n",
            "                                                                 \n",
            " leaky_re_lu_59 (LeakyReLU)  (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_35 (Conv2D)          (None, 32, 32, 3)         867       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 920515 (3.51 MB)\n",
            "Trainable params: 920515 (3.51 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Model: \"GAN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Generator (Sequential)      (None, 32, 32, 3)         920515    \n",
            "                                                                 \n",
            " discriminator (Sequential)  (None, 1)                 23489     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 944004 (3.60 MB)\n",
            "Trainable params: 920515 (3.51 MB)\n",
            "Non-trainable params: 23489 (91.75 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Build Discriminator\n",
        "discriminator = define_discriminator((32,32,3),'discriminator')\n",
        "discriminator.summary()\n",
        "\n",
        "#Build Generator\n",
        "generator = define_generator(100,'Generator')\n",
        "generator.summary()\n",
        "\n",
        "#Build GAN\n",
        "gan = define_gan(generator, discriminator,'GAN')\n",
        "gan.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nr7Sao8zSkI3"
      },
      "source": [
        "**Train Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TZp2zkMsPzE",
        "outputId": "96251b21-5fd8-4e1b-c497-43fe71b14438"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'GANProject' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/chaot/Anaconda3/envs/GANProject/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "dlossavg = []\n",
        "glossavg = []\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for i in range(n_epochs):\n",
        "    print(\"Epoch: \" + str(i))\n",
        "    totaldloss = 0\n",
        "    totalgloss = 0\n",
        "    for j in range(bat_per_epo):\n",
        "\n",
        "      X_real, y_real = generate_real_samples(train_images, half_batch)\n",
        "      X_fake, y_fake = generate_fake_samples(generator, latent_dim, half_batch)\n",
        "      X, y = np.vstack((X_real, X_fake)), np.vstack((y_real, y_fake))\n",
        "      d_loss, _ = discriminator.train_on_batch(X, y)\n",
        "\n",
        "      X_gan = np.random.randn(latent_dim * batch_size)\n",
        "      X_gan = X_gan.reshape(batch_size, latent_dim)\n",
        "      y_gan = np.ones((batch_size, 1))\n",
        "      g_loss = gan.train_on_batch(X_gan, y_gan)\n",
        "\n",
        "      #print('>%d, %d/%d, d=%.3f, g=%.3f' % (i+1, j+1, bat_per_epo, d_loss, g_loss))\n",
        "\n",
        "      totaldloss = totaldloss + d_loss\n",
        "      totalgloss = totalgloss + g_loss\n",
        "\n",
        "    totaldloss = totaldloss / (bat_per_epo-1)\n",
        "    totalgloss = totalgloss / (bat_per_epo-1)\n",
        "\n",
        "    dlossavg.append(totaldloss)\n",
        "    glossavg.append(totalgloss)\n",
        "\n",
        "    if (i+1) % 10 == 0:\n",
        "      evaluate(i, generator, discriminator, train_images, latent_dim)\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "writetxt('Gen_loss',glossavg)\n",
        "writetxt('Dis_loss',dlossavg)\n",
        "\n",
        "print('Training Time', end_time-start_time)\n",
        "print('First Values', dlossavg[0], glossavg[0])\n",
        "print('Last Values', dlossavg[-1], glossavg[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2g8UyXxl4lxj"
      },
      "source": [
        "#Test GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "ZfZq5GSB7haK",
        "outputId": "d04d7ac6-42b6-43bb-e75c-2703ae236610"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'GANProject' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/chaot/Anaconda3/envs/GANProject/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "#model = load_model('generator_model_020.h5')\n",
        "model = generator\n",
        "\n",
        "vector = np.random.randn(100 * 1)\n",
        "vector = vector.reshape(1, 100)\n",
        "\n",
        "X = model.predict(vector)\n",
        "\n",
        "plt.imshow(X[0, :, :, :])\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
